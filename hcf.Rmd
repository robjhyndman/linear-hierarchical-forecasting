---
title: "A fast and elegant method for forecast reconciliation using linear forecasting models"
author:
- familyname: Ashouri
  othernames: Mahsa
  address: Institute of Service Science, National Tsing Hua University, Taiwan
  email: mahsa.ashouri@iss.nthu.edu.tw
  correspondingauthor: true
- familyname: Hyndman
  othernames: Rob J
  address: Monash University, Clayton VIC 3800, Australia
  email: rob.hyndman@monash.edu
- familyname: Shmueli
  othernames: Galit
  address: Institute of Service Science, National Tsing Hua University, Taiwan
  email: galit.shmueli@iss.nthu.edu.tw
abstract: "Forecasting hierarchical or grouped time series involves two steps: computing base forecasts and reconciling the forecasts. Base forecasts can be computed by popular time series forecasting methods such as Exponential Smoothing (ETS) and Autoregressive Integrated Moving Average (ARIMA) models. The reconciliation step is a linear process that adjusts the base forecasts to ensure they are coherent. However using ETS or ARIMA for base forecasts can be computationally challenging when there are a large number of series to forecast, as each model must be numerically optimized for each series. We propose a linear model that avoids this computational problem, and uses a single-step approach to obtain the forecasts, rather than the usual two-step approach. The proposed method is very flexible in incorporating external data and handling missing values. We illustrate our approach using two datasets: monthly Australian domestic tourism and daily Wikipedia pageviews. We compare our approach to reconciliation using ETS and ARIMA, and show that our approach is much faster while providing similar levels of forecast accuracy."
keywords: "hierarchical forecasting, grouped forecasting, reconciling forecast, linear regression"
wpnumber: no/yr
jelcodes: C10,C14,C22
blind: false
cover: false
toc: false
bibliography: references.bib
biblio-style: authoryear-comp
output:
  MonashEBSTemplates::workingpaper:
    fig_caption: yes
    fig_height: 5
    fig_width: 8
    includes:
      in_header: preamble.tex
    keep_tex: yes
    number_sections: yes
    citation_package: biblatex
---

```{r setup, include=FALSE,message=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = TRUE, messages = FALSE, warning = FALSE)
library(ggplot2)
library(knitr)
library(kableExtra)
```

# Introduction


Modern data collection tools have dramatically increased the amount of available time series data. For example, the Internet of Things (IoT) and point-of-sale scanning produce huge volumes of time series in a short period of time. Naturally, there is an interest in forecasting these time series, yet forecasting large collections of time series is computationally challenging.

## Hierarchical and grouped time series

In many cases, these time series can be structured and disaggregated based on hierarchies or groups such as geographic location, product type, gender, etc. An example of hierarchical time series is sales in restaurant chains, which can be disaggregated into different stores and then different types of food or drinks. Figure \@ref(fig:hierarchicalexample) shows a schematic of such a hierarchical time series structure with three levels. The top level (level 0) is the total series, formed by aggregating all the bottom level series. In the middle level (level 1), series are aggregations of their own child series; for instance, series A is the aggregation of AA and AB. Finally, the bottom level series (level 2), includes the most disaggregated series.

```{r hierarchicalexample, echo=FALSE, out.width = "280px", out.height= "180px", fig.align="center", fig.cap="An example of a two level hierarchy structure"}
knitr::include_graphics("Paper-Figures/hierarchical_example.jpg")
```

```{r groupexample, echo=FALSE, out.width = "280px", out.height= "180px", fig.align="center", fig.cap="An example of two level grouped structure"}
library(png)
library(grid)
library(gridExtra)
G1 <- rasterGrob(as.raster(readPNG("Paper-Figures/Group_1.png")), interpolate = FALSE)
G2 <- rasterGrob(as.raster(readPNG("Paper-Figures/Group_2.png")), interpolate = FALSE)
grid.arrange(G1, G2, ncol = 2)
```

Grouped time series involve more complicated aggregation structures compared to strictly hierarchical time series. To take the simplest example, suppose we have two grouping factors which are not nested; for example, sex (Male/Female) and city (New York/San Francisco). The disaggregated series for each combination of sex and city can be combined to form city sub-totals, or sex sub-totals. These sub-totals can be combined to give the overall total. Both sub-totals are of interest.

We can think of such structures as hierarchical time series without a unique hierarchy. A schematic of this grouped time series structure is shown in Figure \@ref(fig:groupexample) with two grouping factors, each of two levels (A/B and C/D). The series in this structure can be split first into groups A and B and then subdivided further into C and D (left side), or split first into C and D and then subdivided into A and B (right side). The final disaggregation is identical in both cases, but the middle level aggregates are different.

We use the same notation [following @fpp2] for both hierarchical and grouped time series. We denote the total series at time $t$ by $y_t$, and the series at node $Z$ and time $t$ by $y_{Z,t}$. For describing the relationships between series, we use an $n\times m$ matrix, called the 'summing matrix', denoted by $\bm{S}$, in which $n$ is the overall number of nodes and $m$ is the number of bottom level nodes. For example in Figure \@ref(fig:hierarchicalexample), $n = 7$ and $m = 4$, while in Figure \@ref(fig:groupexample), $n=9$ and $m=4$. Then we can write $\bm{y}_t=\bm{S}\bm{b}_t$, where $\bm{y}_t$ is a vector of all the level nodes at time $t$ and $\bm{b}_t$ is the vector of all the bottom level nodes at time $t$. For the example shown in Figure \@ref(fig:groupexample), the equation can be written as follows:
\begin{equation}\label{eq:Smatrixexample}
\begin{pmatrix}
  y_{t}\\y_{A,t}\\y_{B,t}\\y_{C,t}\\y_{D,t}\\y_{AC,t}\\y_{AD,t}\\y_{BC,t}\\y_{BD,t}
\end{pmatrix} =
\begin{pmatrix}
  1&1&1&1\\1&1&0&0\\0&0&1&1\\1&0&1&0\\0&1&0&1\\1&0&0&0\\0&1&0&0\\0&0&1&0\\0&0&0&1\\
\end{pmatrix}
\begin{pmatrix}
  y_{AC,t}\\y_{AD,t}\\y_{BC,t}\\y_{BD,t}\\
\end{pmatrix}
\end{equation}

## Forecasting hierarchical time series

If we just forecast each series individually, we are ignoring the hierarchical or grouping structure, and the forecasts will not be "coherent" (they will not add up appropriately).

There are several available methods that consider the hierarchical structure information when forecasting time series. These include the top-down [@gross1990disaggregation;@fliedner2001hierarchical], bottom-up [@kahn1998revisiting], middle-out and optimal combination [@hyndman2011optimal] approaches. In the top-down approach, we first forecast the total series and then disaggregate the forecast to form lower level series forecasts based on a set of historical and forecasted proportions [for details see @athanasopoulos2009hierarchical]. In the bottom-up approach, the forecasts in each level of the hierarchy can be computed by aggregating the bottom level series forecasts.  However, we may not get good upper-level forecasts because the most disaggregated series are highly noisy and so their forecasts are usually inaccurate. In the middle-out approach, the process can be started from one of the middle levels and other forecasts can be computed using aggregation for upper levels and disaggregation for lower levels. Finally, optimal combination uses all the $n$ forecasts for all of the series in the entire structure, and then uses an optimization process to reconcile the resulting forecasts. The advantage of the optimal combination method, compared with the other methods, is that it considers all information in the hierarchy, including any  correlations among the series.

In the optimal combination method, reconciled forecasts can be computed using [@mint2018]
\begin{equation}\label{mint}
  \tilde{\bm{y}}_{h}=\bm{S}(\bm{S}'\bm{W}_h^{-1}\bm{S})^{-1}\bm{S}'\bm{W}^{-1}\hat{\bm{y}}_h
\end{equation}
where $\hat{\bm{y}}_h$ represents a vector of $h$-step-ahead base forecasts for all levels of the hierarchy, and $\bm{W}_h$ is the variance matrix of forecast errors for the $h$-step-ahead base forecasts.

The most difficult task is to compute $\bm{W}_h$, but @mint2018 and @hyndman2016fast argue that replacing it by the diagonal of $\bm{W}_1$ gives good results in practice. This is easy to obtain because it is simply the diagonal matrix comprising the residual variances from each of the base forecasts.

The most computationally challenging part of the optimal combination method is to produce all the base forecasts that make up $\hat{\bm{y}}_h$. In many applications, there may be thousands or even millions of individual series, and each of them must be forecast independently. The most popular time series forecasting methods such as ETS and ARIMA models [@fpp2] involve non-linear optimization routines to estimate the parameters via Maximum Likelihood Estimation. Usually, multiple models are fitted for each series, and the best is select by minimizing Akaike's Information Citerion [@akaike1998information]. This computational challenges increases with the number of lower level series as well as in the number of aggregations of interest.

We therefore propose a new approach to compute the base forecasts that is both computationally fast while maintaining an acceptable forecasting accuracy level.

# Proposed approach

Our proposed approach is based on using linear regression models for computing base forecasts. We begin with partitioning the dataset into training and test sets. We denote by $\mathbf{y_t}=\{y_1,y_2,\dots,y_t\}$ and $\mathbf{y_h}=\{y_{t+1},y_{t+2},\dots,y_h\}$ the vector of time series in the training and test set for $h$-step-ahead forecasts in all the levels of hierarchy. The $h$-step-ahead base forecasts and reconciled vectors are denoted by $\mathbf{\widehat{y}_{h}}$ and $\mathbf{\tilde{y}_{h}}$, respectively. We also use $\mathbf{X_t}$ and $\mathbf{X_h}$ to denote the matrices of predictors in the training and test set, respectively.

The linear forecasting Ordinary Least Square (OLS) model is given by:
\begin{equation}\label{eq:linearmodel}
   \mathbf{y_t} = \mathbf{X_t} \boldsymbol{\alpha_h}+\delta_h,
\end{equation}
where $\boldsymbol{\alpha_h}$ is the vector of coefficients and $\delta_h$ is the error term with mean zero and constant variance. We can estimate the reconciled coefficients in two ways: in two steps,  **two-step**, or in single step, **single-step**. The two-step approach we should first estimate $\boldsymbol{\alpha_h}$ using OLS estimation :
\begin{equation}\label{eq:linearcoefficientstwosteps}
   \boldsymbol{\hat{\alpha}_h} = \mathbf{(X_t'X_t)^{-1}X_t'}\mathbf{y_t},
\end{equation}
and then using Equations \@ref(eq:linearcoefficientstwosteps)  and \@ref(eq:reconciledforecasts), we can find the reconciled forecasts:
\begin{equation}\label{eq:reconciledforecaststwosteps}
   \boldsymbol{\tilde{y}_h} = \mathbf{S(S'S)^{-1}S'}\mathbf{X_h}\boldsymbol{\hat{\alpha}_h}.
\end{equation}

We can use Equations \@ref(eq:linearcoefficientstwosteps) and \@ref(eq:reconciledforecaststwosteps) to compute the base forecasts using an OLS forecasting model and then to apply the reconciled forecasts. However because both OLS and reconciliation steps are linear, we can combine these two steps and compute the reconciled forecasts in one step:
\begin{equation}\label{eq:reconciledforecastsonestep}
   \boldsymbol{\tilde{y}_h} = \mathbf{S(S'S)^{-1}S'}\mathbf{X_h}\mathbf{(X_t'X_t)^{-1}X_t'}\mathbf{y_t}
\end{equation}
This single-step reconciliation approach is more parsimonious and elegant.

## OLS predictors

As an example for the $\mathbf{X_t}$ matrix in Equation \@ref(eq:linearmodel), we can refer to the set of predictors proposed in @ashouri2018 for modeling trend, seasonality and autocorrelation by using lagged values ($y_{t-1}$, $y_{t-2}$, \dots) trend variables and seasonal dummy variables as a set of predictors in the linear model. Equation \@ref(eq:linearmodelexample) shows a linear equation of this type which models linear trend, additive seasonality with $m$ seasons, autocorrelation and external data. $t$ is the running index ($t=1,2,\dots$), and $Season_{jt}$ is a dummy variable taking value 1 if time $t$ ($j=1, 2, \dots, m$) is in season $j$, $y_{t-k}$ is the $k$th lagged value for $y_t$ and $z_t$ is the external data. For instance, if we have daily data with day of week seasonality, $m$ would be 7 (6 seasonal dummies and 7 the violation of lags).
\begin{equation}\label{eq:linearmodelexample}
   \begin{split}
   y_t = \alpha_0 + \alpha_1 t + \beta_1 Season_{1t} + \beta_2 Season_{2t} + \cdots + \beta_{m-1} Season_{(m-1)t} +
   \\
   \gamma_1 y_{t-1} + \gamma_2 y_{t-2} + \dots + \gamma_m y_{t-m} + \delta z_t + \epsilon_t
   \end{split}
\end{equation}

While OLS is popular in practice for forecasting time series, it is often frown upon due to its independence assumption. This can cause issue for parametric inference but is less of a problem for forecasting, in fact it often performs sufficiently well for forecasting as can be seen by its popular use in practice.

# Applications

In this section we illustrate our approach two examples, forecasting monthly Australian domestic tourism and forecasting daily Wikipedia pageviews. We compare the forecasting accuracy levels of ETS, ARIMA and the proposed linear OLS forecasting model,  with and without the reconciliation step. For comparing these methods we use the average of Root Mean Square Error (RMSE) across all series and also display box and density plots for forecast errors along with the raw forecast errors.

Since we are using time series lags ($1, \dots, m$) in the linear forecasting model, we cant forecast multiple steps ahead. We therefore apply two methods for generating $h$-step-ahead forecast: In the first model we use 1-step-ahead forecasts and for forecasting the following periods ($t+2,t+3,\dots$) we replace the previous periods with the actual values. This value is known to us because it is in the test set. In our applications, we call this approach '1-step-ahead'. In the second method, we again use 1-step-ahead forecasts but for forecasting the following periods we use the earlier forecasted values. In our applications, we call this approach '$h$-step-ahead forecast'. We also show the computation challenges in all the methods.

## Australian domestic tourism

This dataset has 19 years of monthly visitor nights in Australia by Australian tourists. This measure is used as an indicator of tourism activity [@wickramasuriya2018optimal]. This data were collected by computer-assisted telephone interviews with 120000, Australians aged 15 and up [Research tourism @researchAustralia2005]. In total this dataset includes 304 time series with length 228 each. The hierarchy and grouping structure for this dataset is made using geographical and purpose of travel information.

In this dataset we have three levels of geographical divisions in Australia. In the first level, Australia was divided into seven 'States' including New South Wales (NSW), Victoria (VIC), Queensland (QLD), South Australia (SA), Western Australia (WA), Tasmania (TAS) and Northern Territory (NT). In the second and third levels it is divided into 27 'Zones' and 76 'Regions' (for details about Australia geographical divisions see Figure \@ref(fig:Australiahierarchystructure) and Table \@ref(tab:Australiageographicaldivision)). For 'Purpose' we have four groups: Holiday (Hol), Visiting (Vis), Business (Bis) and Others (Oth). Based on geographical hierarchy and purpose grouping, we end up with 8 levels of hierarchy with 555 series in total. The hierarchy structure which is used in this example includes the following levels:

- Level 0 = Total series
- Level 1 = State
- Level 2 = Zone
- Level 3 = Region
- Level 4 = Purpose
- Level 5 = State $\times$ Purpose
- Level 6 = Zone $\times$ Purpose
- Level 7 = bottom level series

We report the forecast results for all these hierarchy levels, as well as the average RMSE  across all the levels of hierarchy.

In the predictor matrix, for the OLS forecasting model we apply linear trend, 11 dummy variables, and 12 time series lags^[Since the forecasting results are better without the lags, we just use a linear trend and dummy seasonality variables in our linear model for 24-step-ahead model.]. This is intended to capture the monthly seasonality. In addition, before running the model, we partition the data into two parts, training and test sets. We keep the last 24 months periods (2 years) as our test set to forecast and we use the rest as our training set.

```{r Australiahierarchystructure, echo=FALSE, out.width = "450px", out.height= "180px", fig.align="center", fig.cap="Australia geographical hierarchy structure"}
knitr::include_graphics("Paper-Figures/Australian_hierarchy_structure.jpg")
```

```{r  Australiageographicaldivision, echo=FALSE, message = FALSE, results='asis',cache=TRUE}
table1<-matrix(NA,nrow=58,ncol=6)
colnames(table1)<-c("Series","Name","Label","Series","Name","Label")
table1[,1]<-c("Total","1","State","2","3","4","5","6","7","8","Zone","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","Region","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54")
table1[,2]<-c("","Australia","","NSW","VIC","QLD","SA","WA","TAS","NT","","Metro NSW","Nth Coast NSW","Sth Coast NSW","Sth NSW","Nth NSW","ACT","Metro VIC","West Coast VIC","East Coast VIC","Nth East VIC","Nth West VIC","Metro QLD","Central Coast QLD","Nth Coast QLD","Inland QLD","Metro SA","Sth Coast SA","Inland SA","West Coast SA","West Coast WA","Nth WA","Sth WA","Sth TAS","Nth East TAS","Nth West TAS","Nth Coast NT","Central NT","","Sydney","Central Coast","Hunter","North Coast NSW","Northern Rivers Tropical NSW","South Coast","Snowy Mountains","Capital Country","The Murray","Riverina","Central NSW","New England North West","Outback NSW","Blue Mountains","Canberra","Melbourne","Peninsula","Geelong","Western")
table1[,3]<-c("","Total","","A","B","C","D","E","F","G","","AA","AB","AC","AD","AE","AF","BA","BB","BC","BD","BE","CA","CB","CC","CD","DA","DB","DC","DD","EA","EB","EC","FA","FB","FC","GA","GB","","AAA","AAB","ABA","ABB","ABC","ACA","ADA","ADB","ADC","ADD","AEA","AEB","AEC","AED","AFA","BAA","BAB","BAC","BBA")
table1[,4]<-c("Region","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72","73","74","75","76","77","78","79","80","81","82","83","84","85","86","87","88","89","90","91","92","93","94","95","96","97","98","99","100","101","102","103","104","105","106","107","108","109","110","111")
table1[,5]<-c("","Lakes","Gippsland","Phillip Island","General Murray","Goulburn","High Country","Melbourne East","Upper Yarra","Murray East","Wimmera+Mallee","Western Grampians","Bendigo Loddon","Macedon","Spa Country","Ballarat","Central Highlands","Gold Coast","Brisbane","Sunshine Coast","Central Queensland","Bundaberg","Fraser Coast","Mackay","Whitsundays","Northern","Tropical North Queensland","Darling Downs","Outback","Adelaide","Barossa","Adelaide Hills","Limestone Coast","Fleurieu Peninsula","Kangaroo Island","Murraylands","Riverland","Clare Valley","Flinders Range and Outback","Eyre Peninsula","Yorke Peninsula","Australia's Coral Coast","Experience Perth","Australia's SouthWest","Australia's North West","Australia's Golden Outback","Hobart and the South","East Coast","Launceston, Tamar and the North","North West","Wilderness West","Darwin","Kakadu Arnhem","Katherine Daly","Barkly","Lasseter","Alice Springs","MacDonnell")
table1[,6]<-c("","BCA","BCB","BCC","BDA","BDB","BDC","BDD","BDE","BDF","BEA","BEB","BEC","BED","BEE","BEF","BEG","CAA","CAB","CAC","CBA","CBB","CBC","CBD","CCA","CCB","CCC","CDA","CDB","DAA","DAB","DAC","DBA","DBB","DBC","DCA","DCB","DCC","DCD","DDA","DDB","EAA","EAB","EAC","EBA","ECA","FAA","FBA","FBB","FCA","FCB","GAA","GAB","GAC","GBA","GBB","GBC","GBD")
kable(table1, align =c('c','r','c','c','r','c'),format = "latex", booktabs = T,linesep = "",caption = "Australia geographical hierarchy structure")%>%
kable_styling(position = "center",font_size = 9)
```

```{r  Australiageographicalpurposedivision, echo=FALSE, message = FALSE, results='asis',cache=TRUE}
table1<-matrix(NA,nrow=5,ncol=4)
table1[,1]<-c("Australia", "State", "Zone","Region","Total")
table1[,2]<-c("1","7","27","76","111")
table1[,3]<-c("4","28","108","304","444")
table1[,4]<-c("5","35","135","380","555")
kable(table1, align =c('c','c','c','c'),format = "latex", booktabs = T,linesep = "",caption = "Number of Australian domestic tourism series in each level of hierarchy and group structure",
col.names = c("Geographical division","# of series (geographical division)","# of series (purpose of travel)","Total")) %>%
column_spec(1:4, width = "3cm")%>%
kable_styling(position = "center")
```

In Tables \@ref(tab:Tourismdataresulrolling), \@ref(tab:TourismdataresultRMSE) and \@ref(tab:Tourismdatacomputationtime), we have the average RMSE and computation time for the 24-month forecast period. Methods include ETS, ARIMA and our proposed OLS forecasting model. In Table \@ref(tab:Tourismdataresulrolling) we forecast 24 periods by computing 1-step-ahead forecasts and rolling forward month by month. In Table  \@ref(tab:TourismdataresultRMSE) we generated 24-step-ahead forecasts. In these tables we have two parts related to the forecast, with and without reconciliation.

The results in Table  \@ref(tab:Tourismdataresulrolling) and \@ref(tab:TourismdataresultRMSE) show that our proposed OLS forecasting model  produces forecast accuracy similar to ETS and ARIMA,  which are computationally heavy for many time series. Also they show the usefulness of the reconciliation in decreasing the average RMSE in all the three methods. Except for the total series, reconciliation can help in forecasting all the hierarchy levels.

```{r  Tourismdataresulrolling, echo=FALSE, message = FALSE, results='asis',cache=TRUE}
# we can compute the numbers in tables like this also
# error.tourism.1<-read.csv("Paper-Figures/results_Tourism/error.tourism.1.csv",header = TRUE)
# error.tourism.1%>%filter(Level=="level0"&Method=="ARIMA"&Rec=="rec")
table3<-matrix(NA,nrow=8,ncol=7)
table3[,1]<-c("Level 0","Level 1","Level 2","Level 3","Level 4","Level 5","Level 6","Level 7")
table3[,2]<-c("1516.40","511.37","214.81","122.91","675.99","213.06","97.53","56.17")
table3[,3]<-c("1445.49","493.14","219.01","125.08","709.22","220.08","102.41","58.20")
table3[,4]<-c("1415.06","510.83","224.50","123.97","694.50","216.11","101.03","58.17")
table3[,5]<-c("1533.58","495.88","209.16","118.67","668.26","210.64","96.36","55.98")
table3[,6]<-c("1453.44","457.65","207.52","120.52","679.74","209.39","99.77","57.68")
table3[,7]<-c("1454.39"," 488.33","212.44","119.52","678.54","211.13","98.56","57.20")
kable(table3, align =c('c','c','c','c','c','c','c'),format = "latex", booktabs = T,linesep = "",caption = "Mean(RMSE) for ETS, ARIMA and OLS with and without reconciliation - 1-step-ahead - Tourism dataset", col.names = c("","ETS","ARIMA","OLS","ETS","ARIMA","OLS")) %>%
add_header_above(c("", "Unreconciled" = 3, "Reconciled" = 3)) %>%
add_header_above(c("", "Mean(RMSE)" = 6)) %>%
kable_styling(position = "center")
```

In Figures \@ref(fig:boxplotrollingtourism), \@ref(fig:boxplottourism),  \@ref(fig:densityplotrollingtourism) and \@ref(fig:densityplottourism) we display the error box plots for both reconciled and unreconciled forecasts, and error density plots for reconciled forecasts using all three methods, for 1-step-ahead and 24-step-ahead. In all these figures we see the error distribution similarity across all the models, as well as usefulness of the reconciliation step in improving the forecasts. By comparing density plots \@ref(fig:densityplotrollingtourism) and \@ref(fig:densityplottourism), as could be expected, we  see that by applying 1-step-ahead forecasts, the error densities are closer and more distributed around zero.

```{r echo=FALSE, results='hide',message=FALSE,warning=FALSE,cache=TRUE}
library(ggplot2)
library(gridExtra)
library(dplyr)
## 1-step-ahead
error.tourism<-read.csv("Paper-Figures/results_Tourism/error.tourism.csv",header = TRUE)
error.tourism.1<-error.tourism[error.tourism$ForecastInterval=="1Step",]
error.tourism.1$id <- paste(error.tourism.1$Method, error.tourism.1$Rec, sep=".")
error.tourism.1$order.id = factor(error.tourism.1$id, levels=c("ETS.rec","ETS.unrec","ARIMA.rec","ARIMA.unrec","OLS.rec","OLS.unrec"), labels=c("ETS.rec","ETS.unrec","ARIMA.rec","ARIMA.unrec","OLS.rec","OLS.unrec"))
error.tourism.1.rec<-error.tourism.1[error.tourism.1$Rec=="rec",]
pdf("Paper-Figures/results_Tourism/boxplot_1.pdf",width = 10,height = 10)
ggplot() +
  geom_boxplot(data = error.tourism.1,
               aes(x = order.id, y = (Value),fill=id),
               alpha = 0.5) +
  xlab("Method") + ylab("Error") +
  facet_wrap(~Level,ncol=4,scales = "free_y")+
  guides(fill = guide_legend(nrow = 1, bycol = TRUE)) +
  theme_minimal() +
  scale_fill_manual(values = c("ETS.rec"="green","ETS.unrec"="lightgreen","ARIMA.rec" = "blue", "ARIMA.unrec" = "lightblue","OLS.rec"="pink4","OLS.unrec"="pink"))+
  theme(axis.text.x=element_text(angle=45, hjust=1),axis.text=element_text(size=10),
        axis.title=element_text(size=12,face="bold"),legend.position="none")
# ggplot(error.tourism.1, aes(x=order.id, y=Value, color=id)) +
#   geom_jitter( width=0.1) +
#   geom_point(stat="summary", fun.y="mean",color="black") +
#   geom_errorbar(stat="summary", fun.data="mean_se", fun.args = list(mult = 1.96), width=0,color="black") +
#   labs(x="Method", y="mean + 95%CI") +
#   theme_bw() +
#   facet_wrap(~Level,scales = 'free_y',ncol=2)+
#   scale_color_manual(values = c("ets.rec"="lightblue","ets.unrec"="gray","ARIMA.rec" = "lightblue", "ARIMA.unrec" = "gray","OLS.rec"="lightblue","OLS.unrec"="gray"))+
#   theme(axis.text.x=element_text(angle=45, hjust=1),axis.text=element_text(size=10),
#         axis.title=element_text(size=12,face="bold"),legend.position="none")
dev.off()
pdf("Paper-Figures/results_Tourism/densityplot_1.pdf",width = 10,height = 10)
ggplot() +
  geom_density(data = error.tourism.1.rec, aes(x = (Value), fill = order.id) , alpha =
                 0.3)+
  xlab("Method") + ylab("Error") +
  guides(fill = guide_legend(nrow = 1, byrow = TRUE,title = "Method")) +
  facet_wrap(~Level,ncol=1,scales = "free_y")+
  theme_minimal() +
  theme(
    text  = element_text(size = 12,face="bold"),
    legend.direction = "vertical",
    legend.position = "bottom"
  )+
scale_fill_manual(values = c("ETS.rec"="green","ARIMA.rec" = "blue","OLS.rec"="pink4"))+
xlim(c(-1000, 3000))
dev.off()
forecast.tourism<-read.csv("Paper-Figures/results_Tourism/forecast.tourism.csv",header = TRUE)
forecast.tourism.1<-forecast.tourism[forecast.tourism$ForecastInterval=="1Step",]
### one of the bottom level series
BACBus.1<-forecast.tourism.1%>%
  filter(Series=="BACBus")
p1<-ggplot(BACBus.1, aes(date)) +
  geom_line(aes(y =Actual , colour = "Actual"),size=0.6) +
  geom_line(aes(y =ETS.rec , colour = "ETS.rec"),size=0.6) +
  geom_line(aes(y =ARIMA.rec , colour = "ARIMA.rec"),size=0.6)+
  geom_line(aes(y =OLS.rec , colour = "OLS.rec"),size=0.6)+
  geom_line(aes(y =OLSX.rec , colour = "OLSX.rec"),size=0.6)+
  geom_line(aes(y =ARIMAX.rec , colour = "ARIMAX.rec"),size=0.6)+
  geom_line(aes(y =ETS.unrec , colour = "ETS.unrec"),linetype="dashed",size=0.6) +
  geom_line(aes(y =ARIMA.unrec , colour = "ARIMA.unrec"),linetype="dashed",size=0.6)+
  geom_line(aes(y =OLS.unrec , colour = "OLS.unrec"),linetype="dashed",size=0.6)+
  geom_line(aes(y =OLSX.unrec , colour = "OLSX.unrec"),linetype="dashed",size=0.6)+
  geom_line(aes(y =ARIMAX.unrec , colour = "ARIMAX.unrec"),linetype="dashed",size=0.6)+
  scale_color_manual(name="Series",values = c( Actual="black",ETS.rec="green",ARIMA.rec="blue",OLS.rec="red",OLSX.rec="yellow",ARIMAX.rec="orchid1", ETS.unrec="green",ARIMA.unrec="blue",OLS.unrec="red",OLSX.unrec="yellow",ARIMAX.unrec="orchid1")
                     )+
  guides(colour = guide_legend(override.aes = list(linetype = c("solid","solid","dashed","solid","dashed","solid","dashed","solid","dashed","solid","dashed")),ncol=2))+
  ggtitle("1-step-ahead")+
  xlab("")+
  ylab("Series")+
  theme_bw()+
   theme(legend.text=element_text(size=rel(0.5)))#,legend.position="none")
pdf("Paper-Figures/results_Tourism/forecast_compare_tourism_1.pdf",width = 10,height = 5)
p1
dev.off()
```

```{r  boxplotrollingtourism, echo=FALSE, out.width = "450px", out.height= "300px", fig.align="center", fig.cap="Box plot for forecast errors -  Reconciled and unreconciled ETS, ARIMA and OLS in each hierarchy level for 1-step-ahead tourism demand"}
knitr::include_graphics("Paper-Figures/results_Tourism/boxplot_1.pdf")
```

```{r  densityplotrollingtourism, echo=FALSE, out.width = "450px", out.height= "550px", fig.align="center", fig.cap="Density plot for forecast errors -  Reconciled and unreconciled ETS, ARIMA and OLS in each hierarchy level for 1-step-ahead tourism demand using interval (-1000,3000)"}
knitr::include_graphics("Paper-Figures/results_Tourism/densityplot_1.pdf")
```

```{r  TourismdataresultRMSE, echo=FALSE, message = FALSE, results='asis',cache=TRUE}
table3<-matrix(NA,nrow=8,ncol=7)
table3[,1]<-c("Level 0","Level 1","Level 2","Level 3","Level 4","Level 5","Level 6","Level 7")
table3[,2]<-c("2238.58","593.57","239.52","132.58","766.78","226.74","103.02","59.12")
table3[,3]<-c("3553.99","570.13","229.64","129.40","824.00","241.18","105.38","58.81")
table3[,4]<-c("4194.26","827.67","275.99","144.01","1274.00","285.63","112.20","62.54")
table3[,5]<-c("2250.22","553.76","234.21","126.74","795.48","222.48","101.95","58.54")
table3[,6]<-c("3179.39","626.32","242.46","129.40","958.24","236.94","103.93","58.71")
table3[,7]<-c("4194.21","827.67","275.99","144.02","1274.01","285.63","112.19","62.55")
kable(table3, align =c('c','c','c','c','c','c','c'),format = "latex", booktabs = T,linesep = "",caption = "Mean(RMSE) for ETS, ARIMA and OLS with and without reconciliation - 24-step-ahead - Tourism dataset", col.names = c("","ETS","ARIMA","OLS","ETS","ARIMA","OLS")) %>%
add_header_above(c("", "Unreconciled" = 3, "Reconciled" = 3)) %>%
add_header_above(c("", "Mean(RMSE)" = 6)) %>%
kable_styling(position = "center")
```

```{r echo=FALSE, results='hide',message=FALSE,warning=FALSE,cache=TRUE}
library(ggplot2)
library(grid)
library(gridExtra)
## 24-step-ahead
error.tourism<-read.csv("Paper-Figures/results_Tourism/error.tourism.csv",header = TRUE)
error.tourism.24<-error.tourism[error.tourism$ForecastInterval=="24Step",]
error.tourism.24$id <- paste(error.tourism.24$Method, error.tourism.24$Rec, sep=".")
error.tourism.24$order.id = factor(error.tourism.24$id, levels=c("ETS.rec","ETS.unrec","ARIMA.rec","ARIMA.unrec","OLS.rec","OLS.unrec"), labels=c("ETS.rec","ETS.unrec","ARIMA.rec","ARIMA.unrec","OLS.rec","OLS.unrec"))
error.tourism.24.rec<-error.tourism.24[error.tourism.24$Rec=="rec",]
pdf("Paper-Figures/results_Tourism/boxplot_24.pdf",
    width = 10,
    height = 10)
ggplot() +
  geom_boxplot(data = error.tourism.24,
               aes(x = order.id, y = (Value),fill=id),
               alpha = 0.5) +
  xlab("Method") + ylab("Error") +
  facet_wrap(~Level,ncol=4,scales = "free_y")+
  guides(fill = guide_legend(nrow = 1, bycol = TRUE)) +
  theme_minimal() +
  scale_fill_manual(values = c("ETS.rec"="green","ETS.unrec"="lightgreen","ARIMA.rec" = "blue", "ARIMA.unrec" = "lightblue","OLS.rec"="pink4","OLS.unrec"="pink"))+
  theme(axis.text.x=element_text(angle=45, hjust=1),axis.text=element_text(size=10),
        axis.title=element_text(size=12,face="bold"),legend.position="none")
dev.off()
pdf("Paper-Figures/results_Tourism/densityplot_24.pdf",width = 10,height = 10)
ggplot() +
  geom_density(data = error.tourism.24.rec, aes(x = (Value), fill = order.id) , alpha =
                 0.3)+
  xlab("Method") + ylab("Error") +
  guides(fill = guide_legend(nrow = 1, byrow = TRUE,title = "Method")) +
  facet_wrap(~Level,ncol=1,scales = "free_y")+
  theme_minimal() +
  theme(
    text  = element_text(size = 12,face="bold"),
    legend.direction = "vertical",
    legend.position = "bottom"
  )+
scale_fill_manual(values = c("ETS.rec"="green","ARIMA.rec" = "blue","OLS.rec"="pink4"))+
xlim(c(-1000, 3000))
dev.off()
forecast.tourism<-read.csv("Paper-Figures/results_Tourism/forecast.tourism.csv",header = TRUE)
forecast.tourism.24<-forecast.tourism[forecast.tourism$ForecastInterval=="24Step",]
### one of the bottom level series
BACBus.24<-forecast.tourism.24%>%
  filter(forecast.tourism.24$Series=="BACBus")
p2<-ggplot(BACBus.24, aes(date)) +
  geom_line(aes(y =Actual , colour = "Actual"),size=0.6) +
  geom_line(aes(y =ETS.rec , colour = "ETS.rec"),size=0.6) +
  geom_line(aes(y =ARIMA.rec , colour = "ARIMA.rec"),size=0.6)+
  geom_line(aes(y =OLS.rec , colour = "OLS.rec"),size=0.6)+
  geom_line(aes(y =OLSX.rec , colour = "OLSX.rec"),size=0.6)+
  geom_line(aes(y =ARIMAX.rec , colour = "ARIMAX.rec"),size=0.6)+
  geom_line(aes(y =ETS.unrec , colour = "ETS.unrec"),linetype="dashed",size=0.6) +
  geom_line(aes(y =ARIMA.unrec , colour = "ARIMA.unrec"),linetype="dashed",size=0.6)+
  geom_line(aes(y =OLS.unrec , colour = "OLS.unrec"),linetype="dashed",size=0.6)+
  geom_line(aes(y =OLSX.unrec , colour = "OLSX.unrec"),linetype="dashed",size=0.6)+
  geom_line(aes(y =ARIMAX.unrec , colour = "ARIMAX.unrec"),linetype="dashed",size=0.6)+
  scale_color_manual(name="Series",values = c( Actual="black",ETS.rec="green",ARIMA.rec="blue",OLS.rec="red",OLSX.rec="yellow",ARIMAX.rec="orchid1", ETS.unrec="green",ARIMA.unrec="blue",OLS.unrec="red",OLSX.unrec="yellow",ARIMAX.unrec="orchid1")
                     )+
  guides(colour = guide_legend(override.aes = list(linetype = c("solid","solid","dashed","solid","dashed","solid","dashed","solid","dashed","solid","dashed")),ncol=2))+
  ggtitle("24-step-ahead")+
  xlab("")+
  ylab("Series")+
  theme_bw()+
   theme(legend.text=element_text(size=rel(0.5)))#,legend.position="bottom")
pdf("Paper-Figures/results_Tourism/forecast_compare_tourism_24.pdf",width = 10,height = 5)
p2
dev.off()
```

```{r  boxplottourism, echo=FALSE, out.width = "450px", out.height= "300px", fig.align="center", fig.cap="Box plot for forecast errors -  Reconciled and unreconciled ETS, ARIMA and OLS in each hierarchy level for 24-step-ahead tourism demand"}
knitr::include_graphics("Paper-Figures/results_Tourism/boxplot_24.pdf")
```

```{r  densityplottourism, echo=FALSE, out.width = "450px", out.height= "550px", fig.align="center", fig.cap="Density plot for forecast errors -  Reconciled and unreconciled ETS, ARIMA and OLS in each hierarchy level for 24-step-ahead tourism demand using interval (-1000,3000)"}
knitr::include_graphics("Paper-Figures/results_Tourism/densityplot_24.pdf")
```

Table \@ref(tab:Tourismdatacomputationtime) compares the three methods, computation time for 1-step-ahead and 24-step-ahead forecasting. We see that the OLS forecasting model is much faster compared with the other methods. Also, since reconciliation is a linear process, in all methods, it is very fast and does not affect computation time significantly.

```{r  Tourismdatacomputationtime, echo=FALSE, results='asis',message = FALSE, cache=TRUE}
table2<-matrix(NA,nrow=3,ncol=5)
table2[,1]<-c("ETS","ARIMA","OLS")
table2[,2]<-c("10924.57","31146.38","48.40")
table2[,3]<-c("10924.60","31146.52","48.31")
table2[,4]<-c("407.10","1116.15","16.66")
table2[,5]<-c("407.15","1116.19","16.85")
kable(table2, align =c('c','c'),format = "latex", booktabs = T,linesep = "",caption = "Computation time (seconds) for ETS, ARIMA and OLS with and without reconciliation - 1- and 24-step-ahead - Tourism dataset",
col.names = c("","Unreconciled","Reconciled","Unreconciled","Reconciled")) %>%
column_spec(1:3, width = "3cm")%>%
#row_spec(1,bold=TRUE,italic = T,color = "gray")%>%
#row_spec(5,bold=TRUE,italic = T,color = "gray")%>%
add_header_above(c("", "1-step-ahead" = 2, "24-step-ahead" = 2)) %>%
add_header_above(c("", "Computation time (secs)" = 4)) %>%
kable_styling(position = "center",full_width = F)
```

Now since we are using linear model for forecasting, in this part we are including the 'easter' information to check its effect on forecasting results. We also add this information on ARIMA models and compare with OLS forecasting model. In Tables \@ref(tab:easterroolingRMSE) and \@ref(tab:easterRMSE), we display the average RMSE of ARIMA and OLS including the easter information, ARIMAX and OLSX,  across different levels with and without reconciliation. These tables are for 1-step-ahead and 24-step-ahead forecasts. Figure \@ref(fig:forecstrolling24tourism) shows the 1-step-ahead and 24-step-ahead forecast results for one of the bottom level series, BACBus (Geelong - Business). In these plots we have both reconciled (solid lines) and unreconciled (dashed lines) forecasts and we see that the reconciliation step improves the forecasts in this series. We also see that the OLS  model forecast accuracy is similar to the other two methods. As you can see from the results adding this external data could not change the forecasting results significantly. However in different cases, trying different external data can be helpful in improving the forecasting results.

```{r  easterroolingRMSE, echo=FALSE, message = FALSE, results='asis',cache=TRUE}

table3<-matrix(NA,nrow=8,ncol=9)

table3[,1]<-c("Level 0","Level 1","Level 2","Level 3","Level 4","Level 5","Level 6","Level 7")

table3[,2]<-c("1445.49","493.14","219.01","125.08","709.22","220.08","102.41","58.20")
table3[,3]<-c("1415.06","510.83","224.50","123.97","694.50","216.11","101.03","58.17")
table3[,4]<-c("1564.95","500.66","220.91","125.85","702.78","222.07","103.04","58.60")
table3[,5]<-c("1444.49","514.29","225.82","123.69","680.56","215.15","100.93","58.05")
table3[,6]<-c("1453.44","457.65","207.52","120.52","679.74","209.39","99.77","57.68")
table3[,7]<-c("1454.39","488.33","212.44","119.52","678.54","211.13","98.56","57.20")
table3[,8]<-c("1546.53","472.03","210.47","121.02","682.92","211.45","100.53","58.04")
table3[,9]<-c("1487.23","492.68","213.48","119.44","662.45","209.55","98.49","57.15")

kable(table3, align =c('c','c','c','c','c','c','c','c','c'),format = "latex", booktabs = T,linesep = "",caption = "Mean(RMSE) for ARIMAX and OLSX, adding easter information, with and without reconciliation - 1-step-ahead - Tourism dataset", col.names = c("","ARIMA","OLS","ARIMAX","OLSX","ARIMA","OLS","ARIMAX","OLSX")) %>%
add_header_above(c("", "Unreconciled" = 4, "Reconciled" = 4)) %>%
add_header_above(c("", "Mean(RMSE)" = 8)) %>%
kable_styling(position = "center")
```

```{r  easterRMSE, echo=FALSE, message = FALSE, results='asis',cache=TRUE}

table3<-matrix(NA,nrow=8,ncol=9)

table3[,1]<-c("Level 0","Level 1","Level 2","Level 3","Level 4","Level 5","Level 6","Level 7")

table3[,2]<-c("3553.99","570.13","229.64","129.40","824.00","241.18","105.38","58.81")
table3[,3]<-c("4194.26","827.67","275.99","144.01","1274.00","285.63","112.20","62.54")
table3[,4]<-c("3528.13","509.84","235.06","129.39","811.08","232.88","104.73","59.22")
table3[,5]<-c("4215.36","828.10","276.75","144.86","1292.03","289.12","113.01","62.97")
table3[,6]<-c("3179.39","626.32","242.46","129.40","958.24","236.94","103.93","58.71")
table3[,7]<-c("4194.21","827.67","275.99","144.02","1274.01","285.63","112.19","62.55")
table3[,8]<-c("3114.40","603.66","243.76","129.63","930.72","229.59"," 104.50","59.02")
table3[,9]<-c("4215.28","828.09","276.75","144.86","1292.03","289.12","113.00","62.99")

kable(table3, align =c('c','c','c','c','c','c','c','c','c'),format = "latex", booktabs = T,linesep = "",caption = "Mean(RMSE) for ARIMAX and OLSX, adding easter information, with and without reconciliation - 24-step-ahead - Tourism dataset", col.names = c("","ARIMA","OLS","ARIMAX","OLSX","ARIMA","OLS","ARIMAX","OLSX")) %>%
add_header_above(c("", "Unreconciled" = 4, "Reconciled" = 4)) %>%
add_header_above(c("", "Mean(RMSE)" = 8)) %>%
kable_styling(position = "center")
```

```{r  forecstrolling24tourism, echo=FALSE, out.width = "450px", out.height= "300px", fig.align="center", fig.cap="Comparing Actual test set, Reconciled and unreconciled ETS, ARIMA and OLS for BACBus bottom level series for 1-step-ahead and  24-step-ahead tourism demand"}
grid.arrange(p1, p2, nrow = 2)
```

## Wikipedia pageviews

The second dataset consists of one year of daily data (2016-06-01 to 2017-06-29) on Wikipedia pageviews for the most popular social networks articles [@ashouri2018]. This dataset is noisier compared with the Australian monthly tourism data and forecasting its series is more challenging. It has a grouped structure, with grouping attributes: 'Agent': Spider, User, 'Access': Desktop, Mobile app, Mobile web, 'Language': en (English), de (German), es (Spanish), zh (Chinese) and 'Purpose': Blogging related, Business, Gaming, General purpose, Life style, Photo sharing, Reunion, Travel, Video (check Table \@ref(tab:wikipediagroupingstructure)). We display the group structure in Table \@ref(tab:wikipediagroupingstructure) and Figure \@ref(fig:wikigroupstructure). In Figure \@ref(fig:wikigroupstructure) we use one  possible hierarchy for this dataset, but the order of the hierarchy can be switched.
The final dataset includes 913 time series, each with length 394. The group structure and different levels include:

- Level 0 = Total
- Level 1 = Agent
- Level 2 = Access
- Level 3 = Language
- Level 4 = Purpose
- Level 5 = bottom level series

For this daily dataset, in the OLS forecasting model we include in the predictor matrix a linear trend, 6 seasonal dummies and 7 lags. We partitioned the data into two parts training and test sets. We used the last 28 days for our test set and the rest for the training set.

```{r  wikipediagroupingstructure, echo=FALSE, message = FALSE, results='asis',cache=TRUE}
table1<-matrix(NA,nrow=13,ncol=4)
colnames(table1)<-c("Series","Name","Series","Name")
table1[,1]<-c("Total","1","Agent","2","3","Access","4","5","6","Language","7","8","9")
table1[,2]<-c("","Social Network","","Spider","User","","Desktop","Mobile app","Mobile web","","en (English)","de (German)","es (Spanish)")
table1[,3]<-c("Language","10","Purpose","11","12","13","14","15","16","17","18","19","")
table1[,4]<-c("","zh (Chinese)","","Blogging related","Business","Gaming","General purpose","Life style","Photo sharing","Reunion","Travel","Video","")
kable(table1, align =c('c','r','c','r'),format = "latex", booktabs = T,linesep = "",caption = "Social networking Wikipedia article grouping structure")%>%
kable_styling(position = "center")
```

```{r wikigroupstructure, echo=FALSE, out.width = "500px", out.height= "250px", fig.align="center", fig.cap="One of the possible hierarchy structures for Wikipedia pageview dataset"}
knitr::include_graphics("Paper-Figures/Wiki_group_structure.jpg")
```

Table \@ref(tab:wikipediadataresulrolling), \@ref(tab:wikipediadataresultRMSE) and  \@ref(tab:wikipediadatacomputationtime) represent the RMSE results and computation time. Although these time series are noisier, still we get acceptable results for the OLS forecasting model compared with ETS and ARIMA. In this case, we get similar results with and without the reconciliation step in the forecasted errors.

Figures \@ref(fig:boxplotrollingwiki) and \@ref(fig:boxplotwiki)  display the forecast error box plot. These plots are for 1-step-ahead and 28-step-ahead forecasts in each level of grouping. Further, we can see that the error distribution is almost similar in all levels across the different methods. The only exception is the Total series, where ETS performs significantly better than ARIMA and OLS. We also note that the reconciliation is less effective.

Figures \@ref(fig:densityplotrollingwiki) and \@ref(fig:densityplotwiki) show the density plots for the forecast errors. For both 1-step-ahead and 28-step-ahead forecasts, we can see the density structure of the forecast errors across ETS, ARIMA and the OLS forecasting model. Except for the Total series which ETS works better, in all the other levels are the models  have similar structure for the forecast errors.

```{r  wikipediadataresulrolling, echo=FALSE, message = FALSE, results='asis',cache=TRUE}
table3<-matrix(NA,nrow=6,ncol=7)
table3[,1]<-c("Level 0","Level 1","Level 2","Level 3","Level 4","Level 5")
table3[,2]<-c("10773.66","8272.92","6524.72","4870.08","5233.50","358.90")
table3[,3]<-c("15060.65","10196.34","6705.03","6333.02","4659.53","238.97")
table3[,4]<-c("15748.18","10623.85","6979.58","7150.13","4675.18","254.98")
table3[,5]<-c("11014.73","7736.88","6257.44","4981.91","5001.40","362.25")
table3[,6]<-c("14276.47","9904.12","7142.49","6369.98","4586.53","241.60")
table3[,7]<-c("15270.23","10673.98","7285.97","7106.11","4650.26","256.11")
kable(table3, align =c('c','c','c','c','c','c','c'),format = "latex", booktabs = T,linesep = "",caption = "Mean(RMSE) for ETS, ARIMA and OLS with and without reconciliation - 1-step-ahead - Wikipedia dataset", col.names = c("","ETS","ARIMA","OLS","ETS","ARIMA","OLS")) %>%
add_header_above(c("", "Unreconciled" = 3, "Reconciled" = 3)) %>%
add_header_above(c("", "Mean(RMSE)" = 6)) %>%
kable_styling(position = "center")
```

```{r echo=FALSE, results='hide',message=FALSE,warning=FALSE,cache=TRUE}
library(ggplot2)
library(gridExtra)
## 1-step-ahead
error.wiki<-read.csv("Paper-Figures/results_Wikipedia/error.wiki.csv",header = TRUE)
error.wiki.1<-error.wiki[error.wiki$ForecastingInterval=="1Step",]
error.wiki.1$id <- paste(error.wiki.1$Method, error.wiki.1$Rec, sep=".")
error.wiki.1$order.id = factor(error.wiki.1$id, levels=c("ETS.rec","ETS.unrec","ARIMA.rec","ARIMA.unrec","OLS.rec","OLS.unrec"), labels=c("ETS.rec","ETS.unrec","ARIMA.rec","ARIMA.unrec","OLS.rec","OLS.unrec"))
error.wiki.1.rec<-error.wiki.1[error.wiki.1$Rec=="rec",]
pdf("Paper-Figures/results_Wikipedia/boxplot_1.pdf",
    width = 10,
    height = 10)
ggplot() +
  geom_boxplot(data = error.wiki.1,
               aes(x = order.id, y = (Value),fill=id),
               alpha = 0.5) +
  xlab("Method") + ylab("Error") +
  facet_wrap(~Level,ncol=3,scales = "free_y")+
  guides(fill = guide_legend(nrow = 1, bycol = TRUE)) +
  theme_minimal() +
  scale_fill_manual(values = c("ETS.rec"="green","ETS.unrec"="lightgreen","ARIMA.rec" = "blue", "ARIMA.unrec" = "lightblue","OLS.rec"="pink4","OLS.unrec"="pink"))+
  theme(axis.text.x=element_text(angle=45, hjust=1),axis.text=element_text(size=10),
        axis.title=element_text(size=12,face="bold"),legend.position="none")
dev.off()
pdf("Paper-Figures/results_Wikipedia/densityplot_1.pdf",width = 10,height = 10)
ggplot() +
  geom_density(data = error.wiki.1.rec, aes(x = (Value), fill = order.id) , alpha =
                 0.3)+
  xlab("Method") + ylab("Error") +
  guides(fill = guide_legend(nrow = 1, byrow = TRUE,title = "Method")) +
  facet_wrap(~Level,ncol=1,scales = "free_y")+
  theme_minimal() +
  theme(
    text  = element_text(size = 12,face="bold"),
    legend.direction = "vertical",
    legend.position = "bottom"
  )+
scale_fill_manual(values = c("ETS.rec"="green","ARIMA.rec" = "blue","OLS.rec"="pink4"))#+
#xlim(c(-3000, 4000))
dev.off()
forecast.wiki<-read.csv("Paper-Figures/results_Wikipedia/forecast.wiki.csv",header = TRUE)
forecast.wiki.1<-forecast.wiki[forecast.wiki$ForecastingInterval=="1Step",]
### one of the bottom level series
mobilewusenGen.1<-forecast.wiki.1%>%
  filter(Series=="desktopusenPho21")
#pdf("Paper-Figures/results_wiki/forecast_wiki_1.pdf",width = 10,height = 10)
G1<-ggplot(mobilewusenGen.1, aes(date)) +
  geom_line(aes(y =Actual , colour = "Actual"),size=0.6) +
  geom_line(aes(y =ETS.rec , colour = "ETS.rec"),size=0.6) +
  geom_line(aes(y =ARIMA.rec , colour = "ARIMA.rec"),size=0.6)+
  geom_line(aes(y =OLS.rec , colour = "OLS.rec"),size=0.6)+
  geom_line(aes(y =ETS.unrec , colour = "ETS.unrec"),linetype="dashed",size=0.6) +
  geom_line(aes(y =ARIMA.unrec , colour = "ARIMA.unrec"),linetype="dashed",size=0.6)+
  geom_line(aes(y =OLS.unrec , colour = "OLS.unrec"),linetype="dashed",size=0.6)+
  scale_color_manual(name="Series",values = c( Actual="black",ETS.rec="green",ARIMA.rec="blue",OLS.rec="red",ETS.unrec="green",ARIMA.unrec="blue",OLS.unrec="red")#,
                    # labels=c("Actual","ETS.rec","ARIMA.rec","OLS.rec","ETS.unrec","ARIMA.unrec","OLS.unrec")
                    )+
  guides(colour = guide_legend(override.aes = list(linetype = c("solid","solid","dashed","solid","dashed","solid","dashed"))))+
  ggtitle("1-step-ahead")+
  xlab("")+
  ylab("Series")+
  theme_bw()
#dev.off()
```

```{r boxplotrollingwiki, echo=FALSE, out.width = "450px", out.height= "300px", fig.align="center", fig.cap="Box plot for forecast errors -  Reconciled and unreconciled ETS, ARIMA and OLS in each hierarchy level for 1-step-ahead Wikipedia pageviews"}
knitr::include_graphics("Paper-Figures/results_Wikipedia/boxplot_1.pdf")
```

```{r  densityplotrollingwiki, echo=FALSE, out.width = "450px", out.height= "550px", fig.align="center", fig.cap="Density plot for forecast errors -  Reconciled and unreconciled ETS, ARIMA and OLS in each hierarchy level for 1-step-ahead Wikipedia pageviews"}
knitr::include_graphics("Paper-Figures/results_Wikipedia/densityplot_1.pdf")
```

```{r  wikipediadataresultRMSE, echo=FALSE, message = FALSE, results='asis',cache=TRUE}
table3<-matrix(NA,nrow=6,ncol=7)
table3[,1]<-c("Level 0","Level 1","Level 2","Level 3","Level 4","Level 5")
table3[,2]<-c("14846.93","13608.73","7117.43","6475.90","5302.74","435.64")
table3[,3]<-c("24298.84","17277.01","10731.97","9580.38","8611.25","390.05")
table3[,4]<-c("29840.58","21165.30","12678.89","12056.62"," 8451.09","389.41")
table3[,5]<-c("14999.18","12240.30","7523.43","6509.03","5307.34"," 437.67")
table3[,6]<-c("24649.91","16810.45","11068.81","9799.11","8239.77","391.22")
table3[,7]<-c("29665.70","21048.06","12811.18","12112.46","8460.35","390.97")
kable(table3, align =c('c','c','c','c','c','c','c'),format = "latex", booktabs = T,linesep = "",caption = "Mean(RMSE) for ETS, ARIMA and OLS with and without reconciliation - 28-step-ahead - Wikipedia dataset", col.names = c("","ETS","ARIMA","OLS","ETS","ARIMA","OLS")) %>%
add_header_above(c("", "Unreconciled" = 3, "Reconciled" = 3)) %>%
add_header_above(c("", "Mean(RMSE)" = 6)) %>%
kable_styling(position = "center")
```

```{r echo=FALSE, results='hide',message=FALSE,warning=FALSE,cache=TRUE}
library(ggplot2)
library(gridExtra)
## 28-step-ahead
error.wiki<-read.csv("Paper-Figures/results_Wikipedia/error.wiki.csv",header = TRUE)
error.wiki.28<-error.wiki[error.wiki$ForecastingInterval=="28Step",]
error.wiki.28$id <- paste(error.wiki.28$Method, error.wiki.28$Rec, sep=".")
error.wiki.28$order.id = factor(error.wiki.28$id, levels=c("ETS.rec","ETS.unrec","ARIMA.rec","ARIMA.unrec","OLS.rec","OLS.unrec"), labels=c("ETS.rec","ETS.unrec","ARIMA.rec","ARIMA.unrec","OLS.rec","OLS.unrec"))
error.wiki.28.rec<-error.wiki.28[error.wiki.28$Rec=="rec",]
pdf("Paper-Figures/results_Wikipedia/boxplot_28.pdf",
    width = 10,
    height = 10)
ggplot() +
  geom_boxplot(data = error.wiki.28,
               aes(x = order.id, y = (Value),fill=id),
               alpha = 0.5) +
  xlab("Method") + ylab("Error") +
  facet_wrap(~Level,ncol=3,scales = "free_y")+
  guides(fill = guide_legend(nrow = 1, bycol = TRUE)) +
  theme_minimal() +
  scale_fill_manual(values = c("ETS.rec"="green","ETS.unrec"="lightgreen","ARIMA.rec" = "blue", "ARIMA.unrec" = "lightblue","OLS.rec"="pink4","OLS.unrec"="pink"))+
  theme(axis.text.x=element_text(angle=45, hjust=1),axis.text=element_text(size=10),
        axis.title=element_text(size=12,face="bold"),legend.position="none")
dev.off()
pdf("Paper-Figures/results_Wikipedia/densityplot_28.pdf",width = 10,height = 10)
ggplot() +
  geom_density(data = error.wiki.28.rec, aes(x = (Value), fill = order.id) , alpha =
                 0.3)+
  xlab("Method") + ylab("Error") +
  guides(fill = guide_legend(nrow = 1, byrow = TRUE,title = "Method")) +
  facet_wrap(~Level,ncol=1,scales = "free_y")+
  theme_minimal() +
  theme(
    text  = element_text(size = 12,face="bold"),
    legend.direction = "vertical",
    legend.position = "bottom"
  )+
scale_fill_manual(values = c("ETS.rec"="green","ARIMA.rec" = "blue","OLS.rec"="pink4"))#+
#xlim(c(-3000, 4000))
dev.off()
forecast.wiki<-read.csv("Paper-Figures/results_Wikipedia/forecast.wiki.csv",header = TRUE)
forecast.wiki.28<-forecast.wiki[forecast.wiki$ForecastingInterval=="28Step",]
### one of the bottom level series
desktopusenPho.28<-forecast.wiki.28%>%
  filter(Series=="desktopusenPho21")
#pdf("Paper-Figures/results_wiki/forecast_wiki_1.pdf",width = 10,height = 10)
G2<-ggplot(desktopusenPho.28, aes(date)) +
  geom_line(aes(y =Actual , colour = "Actual"),size=0.6) +
  geom_line(aes(y =ETS.rec , colour = "ETS.rec"),size=0.6) +
  geom_line(aes(y =ARIMA.rec , colour = "ARIMA.rec"),size=0.6)+
  geom_line(aes(y =OLS.rec , colour = "OLS.rec"),size=0.6)+
  geom_line(aes(y =ETS.unrec , colour = "ETS.unrec"),linetype="dashed",size=0.6) +
  geom_line(aes(y =ARIMA.unrec , colour = "ARIMA.unrec"),linetype="dashed",size=0.6)+
  geom_line(aes(y =OLS.unrec , colour = "OLS.unrec"),linetype="dashed",size=0.6)+
  scale_color_manual(name="Series",values = c( Actual="black",ETS.rec="green",ARIMA.rec="blue",OLS.rec="red",ETS.unrec="green",ARIMA.unrec="blue",OLS.unrec="red")#,
                    # labels=c("Actual","ETS.rec","ARIMA.rec","OLS.rec","ETS.unrec","ARIMA.unrec","OLS.unrec")
                    )+
  guides(colour = guide_legend(override.aes = list(linetype = c("solid","solid","dashed","solid","dashed","solid","dashed"))))+
  ggtitle("28-step-ahead")+
  xlab("")+
  ylab("Series")+
  theme_bw()
#dev.off()
```

```{r boxplotwiki, echo=FALSE, out.width = "450px", out.height= "300px", fig.align="center", fig.cap="Box plot for forecast errors -  Reconciled and unreconciled ETS, ARIMA and OLS in each hierarchy level for 28-step-ahead Wikipedia pageviews"}
knitr::include_graphics("Paper-Figures/results_Wikipedia/boxplot_28.pdf")
```

```{r  densityplotwiki, echo=FALSE, out.width = "450px", out.height= "550px", fig.align="center", fig.cap="Density plot for forecast errors -  Reconciled and unreconciled ETS, ARIMA and OLS in each hierarchy level for 28-step-ahead Wikipedia pageviews"}
knitr::include_graphics("Paper-Figures/results_Wikipedia/densityplot_28.pdf")
```

In Figure \@ref(fig:forecstrolling28wiki), we display results for one of the bottom level series, desktopusenPho (desktop-user-english-photo sharing). The plot shows 1-step-ahead and 28-step-ahead forecast results for ETS, ARIMA and OLS, with (solid lines) and without (dashed lines) applying reconciliation. We see that the OLS forecasting model performs close to the other two methods, and reconciliation improves the forecasts.

```{r  forecstrolling28wiki, echo=FALSE, out.width = "400px", out.height= "300px", fig.align="center", fig.cap="Comparing Actual test set, Reconciled and unreconciled ETS, ARIMA and OLS for desktopusenPho (desktop-user-english-photo sharing)  bottom level series- 1- and  28-step-ahead Wikipedia pageviews"}
grid.arrange(G1, G2, nrow = 2)
```

Lastly, Table \@ref(tab:wikipediadatacomputationtime) presents the computation times for all three methods. ETS and ARIMA are clearly much more computationally heavy compared with OLS. As in the Australian tourism dataset, running reconciliation does not have much effect on computation time.

```{r  wikipediadatacomputationtime, echo=FALSE, results='asis',message = FALSE, cache=TRUE}
table2<-matrix(NA,nrow=3,ncol=5)
table2[,1]<-c("ETS","ARIMA","OLS")
table2[,2]<-c("13963.93","10327.02","82.55")
table2[,3]<-c("13963.96","10327.15","82.62")
table2[,4]<-c("450.89","670.40","35.39")
table2[,5]<-c("450.92","670.44","35.43")
kable(table2, align =c('c','c'),format = "latex", booktabs = T,linesep = "",caption = "Computation time (seconds) for ETS, ARIMA and OLS with and without reconciliation - 1- and 28-step-ahead - Wikipedia dataset",
col.names = c("","Unreconciled","Reconciled","Unreconciled","Reconciled")) %>%
column_spec(1:3, width = "3cm")%>%
add_header_above(c("", "1-step-ahead" = 2, "28-step-ahead" = 2)) %>%
add_header_above(c("", "Computation time (secs)" = 4)) %>%
kable_styling(position = "center",full_width = F)
```

# Conclusion

We proposed a single-step linear approach to forecast hierarchical or grouped time series in a much faster way, but with accuracy that nearly matches that of forecast methods such as ETS and ARIMA. This is especially useful in large collections of time series, as is typical in hierarchical and grouped structures. Although ETS and ARIMA are good in terms of forecasting power and accuracy, they can be computationally heavy when facing large collections of time series in hierarchy. Adding another faster option for calculating base forecasts was our purpose in this research. Here we suggest a linear model, OLS, instead of ETS and ARIMA which is not computationally intensive. We also showed that OLS can compete ETS and ARIMA in terms of forecasting accuracy level. We also note that OLS has the additional practice feature in handling missing data while ETS and ARIMA requires imputation.  One more important feature of our model is the ability to easily include external information such as holiday dummies or other external series. In addition to the computation adjustment, our proposed approach forecasts hierarchical time series in a parsimonious single step whereas other available methods all forecast in two-steps.

# Acknowledgements

The first and third authors of this research were partially funded by Ministry of Science and Technology (MOST), Taiwan [Grant 106-2420-H-007-019].

#References

---
nocite: '@*'
---